'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/kubernetes_basics/','title':"Kubernetes Basics",'content':""});index.add({'id':1,'href':'/docs/environment_setup/','title':"Environment Setup",'content':"Environment Setup #  You should be able to do everything locally from your computer without need of a Jumpbox. We will need some dependencies installed:\nInstall CLIs #    Kubectl  Helm 3  Log In to Cluster #  You will be given instructions in Zoom on how to login\u0026hellip;\nCreate Namespace #  Now that you\u0026rsquo;ve logged in, you\u0026rsquo;ll need your own namespace to work out of.\nFirst, let\u0026rsquo;s look at all of the namespaces currently in the system:\nkubectl get namespaces You should see something like this:\nNAME STATUS AGE default Active 13m But let\u0026rsquo;s create your namespace\nkubectl create namespace YOUR_NAME_HERE Now verify the namespace was created\nkubectl get namespaces By default kubectl commands will use the default namespace. Let\u0026rsquo;s change that to use your namespace\nkubectl config set-context --current --namespace=YOUR_NAME_HERE "});index.add({'id':2,'href':'/docs/pods/','title':"Pods",'content':"Pods #  A pod is the smallest unit of deployment in Kubernetes. It consists of one or more related containers that will deploy together on the same worker node. Pods will share networking and storage across all the grouped containers inside the pod.\nNOTE\nA pod typically only has one container\u0026hellip; but it can contain more than one. Examples would be a sidecar container that does some data initialization or a APM sidecar that pulls application metrics to name just a few.  The simplest way to deploy a pod is declaratively. Run this command:\nkubectl run hello-k8s --restart=Never --image=nicksterling/hello-kubernetes:1 --port=8080 Now let\u0026rsquo;s see the running pod\nkubectl get pods You should see output like the following\nNAME READY STATUS RESTARTS AGE hello-k8s 1/1 Running 0 13s Let\u0026rsquo;s dive into the pod a little bit more and get more details\nkubectl describe pod hello-k8s You should see a lot of output\nName: hello-k8s Namespace: default Priority: 0 Node: kind-worker2/172.19.0.2 Start Time: Mon, 22 Jun 2020 21:32:05 -0600 Labels: run=hello-k8s Annotations: \u0026lt;none\u0026gt; Status: Running IP: 10.244.1.4 IPs: IP: 10.244.1.4 Containers: hello-k8s: Container ID: containerd://1a18e5a6c08ca26e5f2f15576dd7b0f00ef1fca62c46fde42e86eb34305c3f17 Image: nicksterling/hello-kubernetes:1 Image ID: docker.io/nicksterling/hello-kubernetes@sha256:e91f805764b59b877e1d1ac70a678bbb097db1a7613eb8ba59f03e7b5c12e5c1 Port: 8080/TCP Host Port: 0/TCP State: Running Started: Mon, 22 Jun 2020 21:32:05 -0600 Ready: True Restart Count: 0 Environment: \u0026lt;none\u0026gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-bhwkz (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: default-token-bhwkz: Type: Secret (a volume populated by a Secret) SecretName: default-token-bhwkz Optional: false QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 87s default-scheduler Successfully assigned default/hello-k8s to kind-worker2 Normal Pulled 87s kubelet, kind-worker2 Container image \u0026quot;nicksterling/hello-kubernetes:1\u0026quot; already present on machine Normal Created 87s kubelet, kind-worker2 Created container hello-k8s Normal Started 87s kubelet, kind-worker2 Started container hello-k8s Declarative vs Imperative #  Up to this point we\u0026rsquo;ve done everything imperatively. We\u0026rsquo;ve issued commands into the CLI and started up a pod. This is not the recommended way to work with Kubernetes. We recommend telling Kubernetes declaratively using a manifest file the state of what we want and let Kubernetes figure out how to do it.\nLet\u0026rsquo;s remove the pod we\u0026rsquo;ve imperatively created.\nkubectl delete pod hello-k8s Now let\u0026rsquo;s create a manifest file called pod.yml and put this as the contents\napiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: run: hello-k8s name: hello-k8s spec: containers: - image: nicksterling/hello-kubernetes:1 name: hello-k8s ports: - containerPort: 8080 resources: {} dnsPolicy: ClusterFirst restartPolicy: Never status: {} Now let\u0026rsquo;s apply that file\nkubectl apply -f pod.yml We have a pod again! Now up to this point we don\u0026rsquo;t have an easy way to view this in a web browser. We need to expose that as a service. Let\u0026rsquo;s go over that next.\n"});index.add({'id':3,'href':'/docs/services/','title':"Services",'content':"Service Overview #  A service is a way to expose an application running on a pod (or set of pods) as a network service. By default Kubernetes gives pods their own IP addresses and DNS entries but they are not addressable to the outside world.\nThere are three major types of Services\n ClusterIP: The default type of Service in K8s. It will give you a service that other apps inside your cluster can access. There is no external access NodePort: This is most primitive way of getting external traffic to your app. This will open up a port on all the nodes in your cluster and traffic received on this port will forward to the application. LoadBalancer: It leverages your IaaS\u0026rsquo; native LB to expose a cluster resource to an IP address given by the IaaS\u0026rsquo; LB. Ingress: Ok\u0026hellip; it\u0026rsquo;s technically not a service. It\u0026rsquo;s a resource but I would be remiss if I didn\u0026rsquo;t mention it. This is another way to allow traffic into your cluster. It\u0026rsquo;s the most powerful way but also the most complex. It\u0026rsquo;s implemented through a third party proxy like Nginx or HAProxy and are managed via Ingress Controllers. It\u0026rsquo;s essentially a sophisticated router.  Deploy Service #  Now that we have some definitions down let\u0026rsquo;s deploy a service to our pod so we can see it\nLet\u0026rsquo;s deploy it imperatively first\nkubectl expose pod hello-k8s --type=LoadBalancer --port 8080 Let\u0026rsquo;s see what it deployed\nkubectl get svc You should now see your hello-k8s LoadBalancer service.\nOUTPUT Now let\u0026rsquo;s navigate to the External IP at port 8080!\nYou should see this IMAGE HERE\nAgain, we shouldn\u0026rsquo;t deploy anything in a one-off manner. Let\u0026rsquo;s delete this service.\nkubectl delete svc hello-k8s And while we\u0026rsquo;re at it\u0026hellip; delete the pod too.\nkubectl delete po hello-k8s We have a better way of deploying pods\u0026hellip; With Deployments!\n"});index.add({'id':4,'href':'/docs/deployments/','title':"Deployments",'content':"Deployments #  If you delete a pod, it\u0026rsquo;s gone forever. That\u0026rsquo;s not very resilient. Deployments allow us to create pod definitions and manage the lifecycle of that pod. Let\u0026rsquo;s create a deployment.yml file:\napiVersion: apps/v1 kind: Deployment metadata: creationTimestamp: null labels: app: hello-k8s name: hello-k8s spec: replicas: 1 selector: matchLabels: app: hello-k8s strategy: {} template: metadata: creationTimestamp: null labels: app: hello-k8s spec: containers: - image: nicksterling/hello-kubernetes:1 name: hello-kubernetes ports: - containerPort: 8080 resources: {} status: {} And apply it:\nkubectl apply -f deployment.yml Now let\u0026rsquo;s create a loadbalancer.yml service to point to our new Deployment\napiVersion: v1 kind: Service metadata: creationTimestamp: null labels: app: hello-k8s name: hello-k8s spec: ports: - port: 8080 protocol: TCP targetPort: 8080 selector: app: hello-k8s type: LoadBalancer status: loadBalancer: {} And apply it\nkubectl apply -f loadbalancer.yml Scale The Pods #  One thing that you can do is scale the number of pods across your cluster for high availability. In your deployment.yml file look for replicas and increase it to 4\nOnce you\u0026rsquo;ve done that apply the change\nkubectl apply -f deployment.yml Now watch the change\nkubectl get all In the next section we\u0026rsquo;ll focus on updating your app to a newer version with a rolling update.\n"});index.add({'id':5,'href':'/docs/rolling_updates/','title':"Rolling Updates",'content':"Rolling Updates #  Now let\u0026rsquo;s update our app to the latest version. Open up the deployment.yml file and look for the image. Replace the image with this one: nicksterling/hello-kubernetes:2\nOnce you\u0026rsquo;ve made the change apply it:\nkubectl apply -f deployment.yml This will go through and roll out the new image. Go to your app to view the change.\nYou can roll back a deployment to an earlier version if something went wrong. We won\u0026rsquo;t cover that in this workshop but you can find more details here: Rolling Back a Deployment\n"});index.add({'id':6,'href':'/docs/logging/','title':"Logging",'content':"Logging #  Logging is best done when the app exports its logs to STDOUT and STDERR. Kubernetes can pick these up and can stream them to something like Elastic or Splunk.\nTo see the logs for our current deployment, run this:\nkubectl logs -f deployment/hello-k8s --all-containers=true "});index.add({'id':7,'href':'/docs/configmaps/','title':"Config Maps",'content':"Config Maps #  A ConfigMap is an API object used to store non-confidential data in key-value pairs. Pods can consume ConfigMaps as environment variables, command-line arguments, or as configuration files in a volume.\nIn our example, we\u0026rsquo;ll be exposing some values via environment variables.\nFirst, let\u0026rsquo;s create the ConfigMap object\nkind: ConfigMap apiVersion: v1 metadata: name: example-configmap data: # Configuration values can be set as key-value properties database: mongodb database_uri: mongodb://localhost:27017 MESSAGE: \u0026quot;A NEW MESSAGE!\u0026quot; # Or set as complete file contents (even JSON!) keys: | image.public.key=771 rsa.public.key=42 Now add the config map\nkubectl apply -f configmap.yml The nice thing is that you can completely decouple your configuration from your application.\nNow let\u0026rsquo;s leverage these values in our deployment. Your spec portion of the deployment.yml should look like this:\n spec: containers: - image: nicksterling/hello-kubernetes:2 name: hello-kubernetes ports: - containerPort: 8080 envFrom: - configMapRef: name: example-configmap resources: {} Apply the change\nkubectl apply -f deployment.yml "});index.add({'id':8,'href':'/docs/secrets/','title':"Secrets",'content':"Secrets #  If ConfigMaps are used for non-sensitive data, then Secrets are used for sensitive data. Examples include:\n SSH Keys API Keys Database Passwords OAuth Tokens  Secrets are not encrypted\nBefore we go further, secrets are Base64 encoded\u0026hellip; but are NOT encrypted.\nThere are ways to encrypt secrets. We won\u0026rsquo;t cover that in this workshop but one way is by using Vault\n Now let\u0026rsquo;s create a secret.yml file and insert this into it:\napiVersion: v1 kind: Secret metadata: name: mysecret type: Opaque data: username: YWRtaW4= password: MWYyZDFlMmU2N2Rm Now let\u0026rsquo;s consume it in the deployment.yml file. This should now be your spec section:\n spec: containers: - image: nicksterling/hello-kubernetes:2 name: hello-kubernetes ports: - containerPort: 8080 env: - name: SECRET_USERNAME valueFrom: secretKeyRef: name: mysecret key: username - name: SECRET_PASSWORD valueFrom: secretKeyRef: name: mysecret key: password envFrom: - configMapRef: name: example-configmap resources: {} Apply the change\nkubectl apply -f deployment.yml You should see the new environment variables in the UI\n"});index.add({'id':9,'href':'/docs/helm/','title':"Helm",'content':"Helm #  Helm is a package manager for Kubernetes. It allows you to bundle up software and its dependencies and deploy and upgrade it easily. This includes databases, CI/CD tools, Kafka, Elastic, etc.\nFirst let\u0026rsquo;s look at some Helm charts: Bitnami has a great list of open-source charts. Bitnami Helm Charts\nIn this example, we\u0026rsquo;ll deploy a blog platform called Ghost.\n"});index.add({'id':10,'href':'/docs/','title':"Docs",'content':""});})();